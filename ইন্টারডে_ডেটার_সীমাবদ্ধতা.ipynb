{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyNahKaU4s66gC0nurluNCVB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alhasanmolla/Quant-Researcher/blob/main/%E0%A6%87%E0%A6%A8%E0%A7%8D%E0%A6%9F%E0%A6%BE%E0%A6%B0%E0%A6%A1%E0%A7%87_%E0%A6%A1%E0%A7%87%E0%A6%9F%E0%A6%BE%E0%A6%B0_%E0%A6%B8%E0%A7%80%E0%A6%AE%E0%A6%BE%E0%A6%AC%E0%A6%A6%E0%A7%8D%E0%A6%A7%E0%A6%A4%E0%A6%BE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⏱️ ইন্টারডে ডেটার সীমাবদ্ধতা (yfinance অনুযায়ী):\n",
        "\n",
        "\n",
        "* 1 মিনিট: সর্বোচ্চ 7 দিন\n",
        "\n",
        "* 2, 5, 15, 30, 90 মিনিট: সর্বোচ্চ 60 দিন\n",
        "\n",
        "* 1 ঘণ্টা (60 মিনিট): সর্বোচ্চ 730 দিন (প্রায় 2 বছর)\n",
        "\n",
        "* 1 দিন বা তার বেশি: সীমাবদ্ধতা নেই"
      ],
      "metadata": {
        "id": "MefcoMoAFeWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "\n",
        "# 1 মিনিট ইন্টারভালের জন্য (সর্বোচ্চ 7 দিন)\n",
        "data_1m = yf.download('TSLA', period='7d', interval='1m')\n",
        "\n",
        "# 15 মিনিট ইন্টারভালের জন্য (সর্বোচ্চ 60 দিন)\n",
        "data_15m = yf.download('TSLA', period='60d', interval='15m')\n",
        "\n",
        "# 1 ঘণ্টা ইন্টারভালের জন্য (সর্বোচ্চ 730 দিন)\n",
        "data_1h = yf.download('TSLA', period='730d', interval='60m')\n",
        "\n",
        "# দৈনিক ইন্টারভালের জন্য (10 বছর)\n",
        "data_daily = yf.download('TSLA', period='10y', interval='1d')\n"
      ],
      "metadata": {
        "id": "wViuJ2clEDg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_1m.head()"
      ],
      "metadata": {
        "id": "nOas-nsnGAhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_15m.head()"
      ],
      "metadata": {
        "id": "uFNUF6pYFHsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_1h.head()"
      ],
      "metadata": {
        "id": "zhpKVlwhFMJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_daily.head()"
      ],
      "metadata": {
        "id": "anJBrF5BFv_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "\n",
        "# Define your start and end date\n",
        "start_date = \"2025-05-01\"\n",
        "end_date = \"2025-05-09\"\n",
        "\n",
        "# Download 1-minute interval data (max 7 days)\n",
        "data = yf.download(\"TSLA\", start=start_date, end=end_date, interval=\"1m\", prepost=False)\n",
        "\n",
        "# Display the data\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "23qL3X2rGNBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "au56MdGcHC6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J7iDO_LvLHp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ikh9cxbLx8fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W3NL_EAUx8WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_AZd10Yjx8TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cdnVslYUx8Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yH0BNlOmx8N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vY4jZh3Ex8K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3MIq9iCGx8II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LRbr-m9fx8Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vul coding\n"
      ],
      "metadata": {
        "id": "wwKGWiBZLISk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "symbol = \"TSLA\"\n",
        "total_days = 7\n",
        "\n",
        "# আজকের তারিখ\n",
        "end_date = datetime.today()\n",
        "\n",
        "# খালি DataFrame তৈরি\n",
        "full_data = pd.DataFrame()\n",
        "\n",
        "# প্রতি দিনের জন্য আলাদা করে data আনবো\n",
        "for i in range(total_days):\n",
        "    start = end_date - timedelta(days=i+1)\n",
        "    end = end_date - timedelta(days=i)\n",
        "\n",
        "    print(f\"Fetching 1m data for {start.date()}\")\n",
        "\n",
        "    data = yf.download(\n",
        "        symbol,\n",
        "        start=start.strftime('2020-01-10'),\n",
        "        end=end.strftime('2025-01-10'),\n",
        "        interval='1m',\n",
        "        progress=False\n",
        "    )\n",
        "\n",
        "    if not data.empty:\n",
        "        full_data = pd.concat([full_data, data])\n",
        "    else:\n",
        "        print(f\"No data available for {start.date()}\")\n",
        "\n",
        "# ডেটা দেখতে চাইলে:\n",
        "print(full_data)\n"
      ],
      "metadata": {
        "id": "Zzc3XkcIHt_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rmlj9XLlJ7kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TNlOMRF2x-LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6mxafschx-HO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# These codes are all wrong to me."
      ],
      "metadata": {
        "id": "iMs-GqqRyEju"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iI8Laxy14x65"
      },
      "outputs": [],
      "source": [
        "# # Required Libraries\n",
        "# import yfinance as yf\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# import joblib\n",
        "\n",
        "# # Step 1: Download Historical Data\n",
        "# def fetch_data(ticker, period='3mo', interval='1d'):\n",
        "#     data = yf.download(ticker, period=period, interval=interval)\n",
        "#     data.dropna(inplace=True)\n",
        "#     return data\n",
        "\n",
        "# # Step 2: Feature Engineering\n",
        "# def engineer_features(data, strike_prices):\n",
        "#     current_price = data['Close'].iloc[-1]\n",
        "#     features = []\n",
        "#     for strike in strike_prices:\n",
        "#         percent_diff = ((strike - current_price) / current_price) * 100\n",
        "#         norm_prob = np.exp(-0.5 * (percent_diff / 10) ** 2)\n",
        "#         cond_prob = max(0.075, norm_prob / 2)  # heuristic approximation\n",
        "#         features.append([strike, percent_diff, norm_prob, cond_prob])\n",
        "#     return pd.DataFrame(features, columns=['OptionStrikePrice', 'PercentDiff', 'NormDistProb', 'ConditionalProb'])\n",
        "\n",
        "# # Step 3: Create Labels (1 if close is above strike price after 5 days)\n",
        "# def generate_labels(data, strike_prices):\n",
        "#     labels = []\n",
        "#     current_close = data['Close'].iloc[-1]\n",
        "#     try:\n",
        "#         future_close = data['Close'].iloc[-1 - 5]  # 5 trading days ago\n",
        "#     except:\n",
        "#         future_close = current_close  # fallback\n",
        "#     for strike in strike_prices:\n",
        "#         label = int(future_close > strike)\n",
        "#         labels.append(label)\n",
        "#     return labels\n",
        "\n",
        "# # Step 4: Train Model\n",
        "# def train_model(X, y):\n",
        "#     scaler = StandardScaler()\n",
        "#     X_scaled = scaler.fit_transform(X)\n",
        "#     model = LogisticRegression()\n",
        "#     model.fit(X_scaled, y)\n",
        "#     joblib.dump(model, 'option_model.pkl')\n",
        "#     joblib.dump(scaler, 'scaler.pkl')\n",
        "#     return model, scaler\n",
        "\n",
        "# # Step 5: Predict\n",
        "# def predict(model, scaler, X):\n",
        "#     X_scaled = scaler.transform(X)\n",
        "#     return model.predict(X_scaled)\n",
        "\n",
        "# # Main Execution\n",
        "# def main():\n",
        "#     ticker = 'CMG'\n",
        "#     strike_prices = [52.5, 55.0, 57.5, 60.0, 62.5]\n",
        "\n",
        "#     data = fetch_data(ticker)\n",
        "#     X = engineer_features(data, strike_prices)\n",
        "#     y = generate_labels(data, strike_prices)\n",
        "\n",
        "#     model, scaler = train_model(X, y)\n",
        "#     predictions = predict(model, scaler, X)\n",
        "\n",
        "#     X['Predicted'] = predictions\n",
        "#     print(\"\\nOption Prediction Table:\\n\")\n",
        "#     print(X)\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Required Libraries\n",
        "# import yfinance as yf\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# import joblib\n",
        "\n",
        "# # Step 1: Download Historical Data\n",
        "# def fetch_data(ticker, period='3mo', interval='1d'):\n",
        "#     data = yf.download(ticker, period=period, interval=interval)\n",
        "#     data.dropna(inplace=True)\n",
        "#     return data\n",
        "\n",
        "# # Step 2: Feature Engineering\n",
        "# def engineer_features(data, strike_prices):\n",
        "#     current_price = data['Close'].iloc[-1]\n",
        "#     features = []\n",
        "#     for strike in strike_prices:\n",
        "#         percent_diff = ((strike - current_price) / current_price) * 100\n",
        "#         norm_prob = np.exp(-0.5 * (percent_diff / 10) ** 2)\n",
        "#         cond_prob = max(0.075, norm_prob / 2)  # heuristic approximation\n",
        "#         features.append([strike, percent_diff, norm_prob, cond_prob])\n",
        "#     return pd.DataFrame(features, columns=['OptionStrikePrice', 'PercentDiff', 'NormDistProb', 'ConditionalProb'])\n",
        "\n",
        "# # Step 3: Create Labels (1 if close is above strike price after 5 days)\n",
        "# def generate_labels(data, strike_prices):\n",
        "#     labels = []\n",
        "#     # Check if there are at least 6 trading days\n",
        "#     if len(data) < 6:\n",
        "#         raise ValueError(\"Not enough historical data to calculate future close.\")\n",
        "\n",
        "#     # Take close price 5 days in the future from -6\n",
        "#     future_close = data['Close'].iloc[-6]  # 5 days before last data point\n",
        "\n",
        "#     for strike in strike_prices:\n",
        "#         label = 1 if future_close > strike else 0\n",
        "#         labels.append(label)\n",
        "\n",
        "#     return labels\n",
        "\n",
        "# # Step 4: Train Model\n",
        "# def train_model(X, y):\n",
        "#     scaler = StandardScaler()\n",
        "#     X_scaled = scaler.fit_transform(X)\n",
        "#     model = LogisticRegression()\n",
        "#     model.fit(X_scaled, y)\n",
        "#     joblib.dump(model, 'option_model.pkl')\n",
        "#     joblib.dump(scaler, 'scaler.pkl')\n",
        "#     return model, scaler\n",
        "\n",
        "# # Step 5: Predict\n",
        "# def predict(model, scaler, X):\n",
        "#     X_scaled = scaler.transform(X)\n",
        "#     return model.predict(X_scaled)\n",
        "\n",
        "# # Main Execution\n",
        "# def main():\n",
        "#     ticker = 'TSLA'\n",
        "#     strike_prices = [150, 160, 170, 180, 190]\n",
        "\n",
        "#     data = fetch_data(ticker)\n",
        "#     X = engineer_features(data, strike_prices)\n",
        "#     y = generate_labels(data, strike_prices)\n",
        "\n",
        "#     # Make sure y is a 1D array, not Series or DataFrame\n",
        "#     y = np.array(y).ravel()\n",
        "\n",
        "#     if len(y) != len(X):\n",
        "#         raise ValueError(f\"Mismatch between features and labels length. Got features: {len(X)}, labels: {len(y)}\")\n",
        "\n",
        "#     model, scaler = train_model(X, y)\n",
        "#     predictions = predict(model, scaler, X)\n",
        "\n",
        "#     X['Predicted'] = predictions\n",
        "#     print(\"\\nOption Prediction Table:\\n\")\n",
        "#     print(X)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "id": "6nWNNc575uye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Step 1: Download Historical Data with error handling\n",
        "# def fetch_data(ticker, period='5y', interval='1d'):\n",
        "#     try:\n",
        "#         data = yf.download(ticker, period=period, interval=interval, progress=False)\n",
        "#         if data.empty:\n",
        "#             raise ValueError(\"No data returned for the given ticker and period.\")\n",
        "#         data.dropna(inplace=True)\n",
        "#         return data\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error fetching data: {e}\")\n",
        "#         return None"
      ],
      "metadata": {
        "id": "HQnE1bXNDvgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Required Libraries\n",
        "# import yfinance as yf\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.metrics import accuracy_score, classification_report\n",
        "# import joblib\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Technical indicator functions\n",
        "# def compute_rsi(prices, window=14):\n",
        "#     deltas = prices.diff()\n",
        "#     gains = deltas.where(deltas > 0, 0)\n",
        "#     losses = -deltas.where(deltas < 0, 0)\n",
        "\n",
        "#     avg_gain = gains.rolling(window=window, min_periods=1).mean()\n",
        "#     avg_loss = losses.rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "#     rs = avg_gain / avg_loss\n",
        "#     return 100 - (100 / (1 + rs))\n",
        "\n",
        "# def compute_macd(prices, fast=12, slow=26, signal=9):\n",
        "#     exp1 = prices.ewm(span=fast, adjust=False).mean()\n",
        "#     exp2 = prices.ewm(span=slow, adjust=False).mean()\n",
        "#     macd = exp1 - exp2\n",
        "#     signal_line = macd.ewm(span=signal, adjust=False).mean()\n",
        "#     return macd, signal_line\n",
        "\n",
        "# # Step 1: Download Historical Data with error handling\n",
        "# def fetch_data(ticker, period='90d', interval='60m'):\n",
        "#     try:\n",
        "#         data = yf.download(ticker, period=period, interval=interval, progress=False)\n",
        "#         if data.empty:\n",
        "#             raise ValueError(\"No data returned for the given ticker and period.\")\n",
        "#         data.dropna(inplace=True)\n",
        "#         return data\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error fetching data: {e}\")\n",
        "#         return None\n",
        "\n",
        "# # Step 2: Enhanced Feature Engineering\n",
        "# def engineer_features(data, strike_prices):\n",
        "#     current_price = data['Close'].iloc[-1]\n",
        "#     features = []\n",
        "\n",
        "#     # Calculate technical indicators\n",
        "#     data['SMA_5'] = data['Close'].rolling(window=5, min_periods=1).mean()\n",
        "#     data['SMA_20'] = data['Close'].rolling(window=20, min_periods=1).mean()\n",
        "#     data['RSI'] = compute_rsi(data['Close'], 14)\n",
        "#     data['MACD'], data['Signal_Line'] = compute_macd(data['Close'])\n",
        "#     latest_tech = data.iloc[-1][['SMA_5', 'SMA_20', 'RSI', 'MACD', 'Signal_Line']].values\n",
        "\n",
        "#     for strike in strike_prices:\n",
        "#         percent_diff = ((strike - current_price) / current_price) * 100\n",
        "#         norm_prob = np.exp(-0.5 * (percent_diff / 10) ** 2)\n",
        "#         cond_prob = max(0.075, norm_prob / 2)\n",
        "\n",
        "#         # Days to expiration (assuming options expire in 30 days)\n",
        "#         days_to_exp = 30\n",
        "\n",
        "#         # Combine all features\n",
        "#         features.append([\n",
        "#             strike,\n",
        "#             current_price,\n",
        "#             percent_diff,\n",
        "#             norm_prob,\n",
        "#             cond_prob,\n",
        "#             days_to_exp,\n",
        "#             *latest_tech\n",
        "#         ])\n",
        "\n",
        "#     feature_columns = [\n",
        "#         'StrikePrice', 'CurrentPrice', 'PercentDiff', 'NormDistProb', 'ConditionalProb', 'DaysToExpiration',\n",
        "#         'SMA_5', 'SMA_20', 'RSI', 'MACD', 'Signal_Line'\n",
        "#     ]\n",
        "#     return pd.DataFrame(features, columns=feature_columns)\n",
        "\n",
        "# # Step 3: Improved Label Generation with forward-looking window\n",
        "# def generate_labels(data, strike_prices, lookahead_days=5):\n",
        "#     labels = []\n",
        "#     if len(data) < lookahead_days + 1:\n",
        "#         raise ValueError(f\"Need at least {lookahead_days+1} days of data for {lookahead_days}-day prediction\")\n",
        "\n",
        "#     # Get future close (looking forward)\n",
        "#     future_close = data['Close'].shift(-lookahead_days).iloc[0]\n",
        "\n",
        "#     for strike in strike_prices:\n",
        "#         label = 1 if future_close > strike else 0\n",
        "#         labels.append(label)\n",
        "\n",
        "#     return labels\n",
        "\n",
        "# # Step 4: Enhanced Model Training with evaluation\n",
        "# def train_model(X, y):\n",
        "#     # Split data into train and test sets\n",
        "#     X_train, X_test, y_train, y_test = train_test_split(\n",
        "#         X, y, test_size=0.2, random_state=42\n",
        "#     )\n",
        "\n",
        "#     # Scale features\n",
        "#     scaler = StandardScaler()\n",
        "#     X_train_scaled = scaler.fit_transform(X_train)\n",
        "#     X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "#     # Train model\n",
        "#     model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "#     model.fit(X_train_scaled, y_train)\n",
        "\n",
        "#     # Evaluate model\n",
        "#     train_pred = model.predict(X_train_scaled)\n",
        "#     test_pred = model.predict(X_test_scaled)\n",
        "\n",
        "#     print(\"\\nModel Evaluation:\")\n",
        "#     print(\"Training Accuracy:\", accuracy_score(y_train, train_pred))\n",
        "#     print(\"Test Accuracy:\", accuracy_score(y_test, test_pred))\n",
        "#     print(\"\\nClassification Report:\")\n",
        "#     print(classification_report(y_test, test_pred))\n",
        "\n",
        "#     # Save model and scaler\n",
        "#     joblib.dump(model, 'option_model.pkl')\n",
        "#     joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "#     return model, scaler\n",
        "\n",
        "# # Step 5: Enhanced Prediction with probabilities\n",
        "# def predict(model, scaler, X):\n",
        "#     X_scaled = scaler.transform(X)\n",
        "#     predictions = model.predict(X_scaled)\n",
        "#     probabilities = model.predict_proba(X_scaled)[:, 1]  # Probability of class 1\n",
        "#     return predictions, probabilities\n",
        "\n",
        "# # Visualization function\n",
        "# def plot_predictions(results):\n",
        "#     plt.figure(figsize=(12, 6))\n",
        "#     colors = results['Prediction'].map({1: 'green', 0: 'red'})\n",
        "#     plt.scatter(results['StrikePrice'], results['CurrentPrice'],\n",
        "#                 c=colors, s=100, alpha=0.7)\n",
        "#     plt.title('Option Strike Price Predictions')\n",
        "#     plt.xlabel('Strike Price')\n",
        "#     plt.ylabel('Current Price')\n",
        "#     plt.grid(True)\n",
        "\n",
        "#     # Add current price line\n",
        "#     current_price = results['CurrentPrice'].iloc[0]\n",
        "#     plt.axhline(y=current_price, color='blue', linestyle='--', label='Current Price')\n",
        "#     plt.legend()\n",
        "\n",
        "#     plt.show()\n",
        "\n",
        "# # Main Execution with error handling\n",
        "# def main():\n",
        "#     try:\n",
        "#         ticker = 'TSLA'\n",
        "#         strike_prices = [150, 160, 170, 180, 190, 200, 210]\n",
        "\n",
        "#         print(f\"Fetching data for {ticker}...\")\n",
        "#         data = fetch_data(ticker, period='6mo')  # Increased lookback period\n",
        "\n",
        "#         if data is None:\n",
        "#             return\n",
        "\n",
        "#         print(\"Engineering features...\")\n",
        "#         X = engineer_features(data, strike_prices)\n",
        "\n",
        "#         print(\"Generating labels...\")\n",
        "#         y = generate_labels(data, strike_prices, lookahead_days=5)\n",
        "#         y = np.array(y)\n",
        "\n",
        "#         if len(y) != len(X):\n",
        "#             raise ValueError(f\"Mismatch: features {len(X)}, labels {len(y)}\")\n",
        "\n",
        "#         print(\"\\nTraining model...\")\n",
        "#         model, scaler = train_model(X, y)\n",
        "\n",
        "#         print(\"\\nMaking predictions...\")\n",
        "#         predictions, probabilities = predict(model, scaler, X)\n",
        "\n",
        "#         # Create results dataframe\n",
        "#         results = X[['StrikePrice', 'CurrentPrice', 'PercentDiff']].copy()\n",
        "#         results['Prediction'] = predictions\n",
        "#         results['Probability'] = probabilities\n",
        "#         results['Prediction_Text'] = results['Prediction'].map({1: 'In the money', 0: 'Out of money'})\n",
        "\n",
        "#         print(\"\\nOption Prediction Results:\")\n",
        "#         print(results.sort_values('StrikePrice'))\n",
        "\n",
        "#         # Plot results\n",
        "#         plot_predictions(results)\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error in main execution: {e}\")\n",
        "#         raise  # Re-raise the exception to see full traceback\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ],
      "metadata": {
        "id": "dwEUlqcX8D6V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}